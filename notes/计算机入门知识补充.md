# 计算机入门知识补充

from 2024.02.28

## 一、计算机及其早期历史

## 二、电子计算机

1. **机电设备**：哈佛马克一号

   哈佛马克一号 IBM 1944 （给曼哈顿计划跑模拟）：不够快，一秒钟能做三次加减法，1/6次乘法，1/15次触发，且硬件容易出现较多问题。

​	1947从中拔出一只bug

2. **电子计算机**：1903年三极管的诞生，使得继电器可以变得简洁，计算机从机电转入电子。

   巨人一号是第一个使用真空管的计算机（可编程的电子计算机）。

3. **电子数值积分计算机**

​	寻求新的电子开关

4. **晶体管的诞生**

   应用半导体特性，且体积极小，故障少，算力高。IBM最终把晶体管计算机引入家庭。

​	**我们看到继电器——真空管——晶体管的硬件升级，提高计算机算力的历史过程。**

## 三、布尔逻辑和逻辑门

二进制为基础。

True  False or 1 0.

布尔代数：进行逻辑操作，NOT，AND，OR

利用晶体管可以实现与或非，从而实现布尔代数中定义的操作。

## 四、 二进制

一位叫一个bit

1 byte=8 bits

1 mega = 1 million Bytes

1 giga = 1 billion Bytes

32位计算机是指底层处理数据时每32 bits 为一个处理块，数字大小可以达到40亿。第一位0,1表示正负

64位计算机可以表达的最大数为9.2*10 ^ 18

---

### 其他信息的保存办法：

* 浮点数有很多表示办法，最常见的是IEEE 754标准。

![image-20240228162939772](C:\Users\86178\AppData\Roaming\Typora\typora-user-images\image-20240228162939772.png)



​	第一位存正负，接下来八位存指数，剩下存有效位数

* **ASCII（美国信息交换标准代码）：七位代码，可以存128个值。**

​	但是一个字节有八位，剩下一位由各个国家自行使用。一般对于拼写语言，这是够用的；但是对于中文这种几千字符的语言就不行	了。

​	**Unicode的诞生（1992），统一编码（16位），有百万空位，可以容纳所有语言的所有符号。**

* 更一般地，其他信息（音频，图像等）都可以用这种二进制符号来表示。

所以，我们成功地用二进制表示了各种信息。

到这里，我们仅仅解决了如何表示信息的问题。以后我们会解决如何处理这些信息。

## 五、算数逻辑单元（ALU）

Arithmetic and Logic Unit

Intel 74181 第一个被封装在单芯片里的ALU

ALU有两个单元，算数单元和逻辑单元。

### 算数单元

以0+1为例。

> 0+0=0
>
> 0+1=1
>
> 1+0=1
>
> 1+1=10

**两个输入，一个输出**

![image-20240228164630838](C:\Users\86178\AppData\Roaming\Typora\typora-user-images\image-20240228164630838.png)

**对于1+1的情况：**

![image-20240228164758844](C:\Users\86178\AppData\Roaming\Typora\typora-user-images\image-20240228164758844.png)

额外牵一根线表示进位，只有1+1时为True,否则为False

但是1个bit存不下，需要两个输出。

![image-20240228164857752](C:\Users\86178\AppData\Roaming\Typora\typora-user-images\image-20240228164857752.png)

![image-20240228164929968](C:\Users\86178\AppData\Roaming\Typora\typora-user-images\image-20240228164929968.png)

 全加器（Full Adder）：

三个输入，两个输出。（因为有时进位可能会导致三个1 bit 相加，max=1+1+1，所以是两位，可以由半加器叠加组成。）  

以此类推地再组合全加器，又能得到八位加法器（8-bit Ripple Carry Adder）,如果运算结果超出位数，则称为overflow。但是多挂几个全加器就可以拓展位数。

**现代计算机使用的加法运算略有不同，称为超前进位加法器（Carry-Look-Ahead-Adder）。**

同样地，ALU的算数单元也可以做一些其他的数学运算，支持以下：

![image-20240228165734964](C:\Users\86178\AppData\Roaming\Typora\typora-user-images\image-20240228165734964.png)

乘法用多次加法来实现，现代微波炉，遥控器还是使用这种简单的ALU叠加操作（如乘法）的方法。

手机、电脑处理器有不同的ALU处理更复杂的逻辑门。

### 逻辑单元

![image-20240228170436114](C:\Users\86178\AppData\Roaming\Typora\typora-user-images\image-20240228170436114.png)

把各种全加器的组合全部省略掉（不看逻辑门），抽象成了上述符号。

这个系统可以接受操作代码（仍然是二进制形式）用来表示对两个input做的操作，并给出8位输出。ALU同时还会输出flag（状态，1位）

高级ALU有更多状态标志。

## 六、寄存器和内存

在ALU部分我们已经得到处理后的信号输出，问题是，如何将这些信息存起来？

RAM（随机存取存储器，Random Access Memory）vs persistent memory

先从做只能存储1位的电路开始：

![image-20240228171048462](C:\Users\86178\AppData\Roaming\Typora\typora-user-images\image-20240228171048462.png)

一旦A变成0，那么无论B的初始状态是什么，最终输出都将是0，而且这一变化是永久的，无论以后A如何改变。

![image-20240228171149110](C:\Users\86178\AppData\Roaming\Typora\typora-user-images\image-20240228171149110.png)

为了简化，希望能够只有一条设置线用来启动内存，称为允许写入线。如下。

![image-20240228171344599](C:\Users\86178\AppData\Roaming\Typora\typora-user-images\image-20240228171344599.png)

抽象如下：

![image-20240228171422726](C:\Users\86178\AppData\Roaming\Typora\typora-user-images\image-20240228171422726.png)

如果允许写入变成1，则新数据可以写入；否则只输出上次输入的数据的值。

一组**锁存器**可以称为一个**寄存器**，寄存器可以存一个数字，这个数字有多少位叫做“位宽”。

现在的电脑是多少位就是指这个位宽。

我们用矩阵来放置锁存器（latch matrix）:启用锁存器只需要启动对应的行和列（的行列线）以及允许写入线（和所有锁存器相连接），就能实现定点存储。

同样地办法可以做出允许读取线（链接所有锁存器）并读指定锁存器的信息，当且仅当行列线为1且允许读取线为1。

![image-20240228171818958](C:\Users\86178\AppData\Roaming\Typora\typora-user-images\image-20240228171818958.png)

这样，我们要存储256位数据，只需要256（16*16）个锁存器以及16+16+2条线即可。

如何通过地址激活指定锁存器？

用四位表示行，四位表示列，就可以将地址转化成两个四位二进制数。

**多路复用器（multiplexer）**：输入四位地址，输出1行（或列）信号，两个多路复用器实现上述功能。

---

以上我们实现了一个256位内存，现在将其抽象为一个整体。他输入一个8位地址（4位行4位列），并且设置一个允许写入线和一个允许读取线。

 我们将8个这样的256位内存并排放置，每8个bits分别占用里面的每个内存里面的一位空间，总体占用1byte，这样整体就可以存储256 bytes的信息。

![image-20240228212228028](C:\Users\86178\AppData\Roaming\Typora\typora-user-images\image-20240228212228028.png)

我们再把这些组块看成一个整体，就得到了一个整体的可寻址内存，如下。

![image-20240228212323468](C:\Users\86178\AppData\Roaming\Typora\typora-user-images\image-20240228212323468.png)

这个内存仍然是输入八位数字定位一个地址，而这一个地址是8个256内存的并列，正好存储1 byte的信息。

优势：随时查看或存储任何位置的信息。

所以命名：RAM，即随机存取存储器

### SRAM：静态随机存取存储器

可以利用锁存器制作一个SRAM，其他的还有DRAM，闪存和NVRAM等。

## 七、CPU 中央处理器

**微体系架构**（Micro-architecture，高层次视角，只关心功能而忽略细枝末节的具体实现方式）

* **4个寄存器+1块RAM**，前者用来临时存储和操作数据，后者用来存数据

* 可以给CPU支持的**所有指令分配一个ID**，现在的例子中，我们用前四位存操作代码，简称“操作码”，后四位表示数据从哪来，可以是寄存器或者内存地址。

* 另外，我们需要一个**寄存器追踪程序运行到了那里，叫做“指令地址寄存器”**，存当前指令的内存地址。
* **另一个寄存器存当前指令，称为指令寄存器**。

---

执行代码经历的阶段：

1. Fetch Phase：将指令地址寄存器连接到RAM，RAM返回指令地址寄存器中指示的地址对应的值。该值会被复制到指令寄存器。 
2. Decode Phase：前四位和后四位分开，前四位代表instruction，后四位代表地址或寄存器。该指令由控制单元（也是逻辑门组成）解码，并且实现对应操作。
3. Execute Phase：实现。

----

我们把繁复的逻辑门隐去，抽象出控制单元这一组件。

另外，我们再加装一块ALU，使得CPU可以实现计算。

![image-20240228222801272](C:\Users\86178\AppData\Roaming\Typora\typora-user-images\image-20240228222801272.png)

~以上是一个标准组成~

另外需要加装一个时钟，控制所有单元的运行频率。

CPU取指令、解码、执行的速度叫做时钟速度（Clock Speed），单位是Hz。

超频意味着增大时钟速度，降频即减小时钟速度。

根据性能需求改变时钟速度，这叫动态调整频率。

---

我们把以上除了RAM的组件打包由抽象为一个层次，即CPU芯片。



## 八、指令与程序

CPU是可编程的，如果写入不同指令，他就会执行不同的任务。我们说这个硬件可以被软件控制。

在RAM中，指令和数据都以二进制的方式被存储，如果不加以区分将会导致混乱。

Halt：停止指令，标志程序运行结束。（区分指令和数据）

通过jump指令，可以实现小循环，从而实现少指令多操作。

---

为了使得指令能够索引到更大的位置，现代CPU有两种策略：

* 暴力增加位数：32位或64位系统
* 可变指令长度：通过jump增长指令长度，这样操作使得一个指令的长度可以是任意的。

现代的i7处理器可以存上千个指令，长度1-15，这就使得指令可以实现的功能也越来越复杂。



## 九、高级CPU设计

如何通过硬件提高计算速度。

RAM独立于CPU，通过总线传输数据，但是数据量巨大的时候会有延迟。

解决延迟的一个办法就是在CPU中加入**缓存**“cache”，一般是KB或MB起步，这减少了CPU空的情况。

如果想要的数据已经在缓存，这叫做**缓存命中**，即cache hit，否则是缓存未命中。

同样地，存数据也是先存到缓存里，如果接着算会更快。但是这导致了缓存和RAM不同的情况，因此缓存内每个位置都有编号，叫做**Dirty Bit**。同步发生在缓存已满但是仍有新信息的情况。这时在清理缓存之前会先检查Dirty Bit，在加载新内容之前把数据写回RAM。

另一种方案叫做**指令流水线**，即让CPU所有部件同时工作处理不同问题。

此外CPU在执行jump指令时会在空等时间预测指令，如果预测正确则直接取出结果，简洁高效。

超标量处理器：一个时钟周期执行多个指令。

多核处理器：一个CPU中有多个独立计算资源，共用缓存，可以执行更高效的运算。 



## 十、早期程序设计

 1801年，约瑟夫设计的打孔卡纸部件当做指令，执行在纺织机上。

1890年，美国人口普查利用了这个打孔纸理念（汇总数据）。

之后六十年，这些机器被加强，可以执行四则运算。

但是这个年代的机器运行不同程序需要把线插在不同位置，但是插线板编程过于复杂（机电计算机和第一台电子计算机）。

20世纪40年代，内存变得可行，把程序存在内存中显然是更方便的（相比于存在插线板）。这类机器叫做存储程序计算机。程序和数据存在同一个地方，这样的结构被称为**冯诺依曼架构**。但是一直到1980年，计算机仍然用穿孔卡纸读取器把程序写进内存。 

在1980年代前，也存在面板编程。面板上有指示灯用来指示状态和函数等。但是操作复杂，需要引进新的编程语言编写程序。

## 十一、编程语言发展史

软件

机器语言 or 机器码：二进制语言。

最初，用自然语言写好了“伪代码”，需要对照二进制表格写入程序。

20世纪四十年代，程序员开发出了助记符，并且开发程序“汇编器”把汇编语言转化成机器语言。

一般来说，一条汇编语言对应一条机器语言，因此仍然很底层，需要对硬件非常了解。

compiler：编译器

霍普开发编译器使用更高级的语言进行程序编写。

在python中变量是地址的抽象。

1957年IBM开发出FORTRAN语言。

后来，各界自发形成组织：数据系统语言委员会，用来解决程序在不同计算机上不兼容的问题。这需要开发一种通用语言，由此，COBOL诞生。

这时迎来了计算机发展的黄金时期。在20世纪六十年代，流行ALGOL，LISP，BASIC等语言；七十年代，流行Pascal，C以及Smalltalk等，80年代：C++，Objective-C，Perl等。90年代，Python，Ruby和Java。

## 十二、编程原理：语句与函数

规定句子结构的规则是语法，编程语言有自己的语法。

赋值语句把值赋给变量。

> 下面省略大量关于数据结构和算法的问题。 
